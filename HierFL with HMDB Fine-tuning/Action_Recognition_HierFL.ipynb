{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Action Recognition HierFL",
      "provenance": [],
      "collapsed_sections": [
        "lgsYQ88lSKkv",
        "5_AldiSTWkVM",
        "gEOyesH_SUfv",
        "07_OZH7CVqoC",
        "egmwTD8VVcXb",
        "zK5SsDncVd2z",
        "-1syuZvMVflc",
        "nH2w8cLUZIwE",
        "AZooih5T4F18",
        "qoMZfemk3_M_"
      ]
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Brvzk1Ko0wiQ"
      },
      "source": [
        "## TO DO List\n",
        "#### Add LR scheduler\n",
        "#### Implement KD with TA"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lgsYQ88lSKkv"
      },
      "source": [
        "# Libraries and Data Preparation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8eZnCbY9OPty"
      },
      "source": [
        "# Install dependencies for video module in pytorch to work\n",
        "! apt-get install libavformat-dev libavdevice-dev\n",
        "! pip install av==6.2.0"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LyP_eyA5OYDs"
      },
      "source": [
        "# Download HMDB51 data and splits from serre lab website\n",
        "! wget http://serre-lab.clps.brown.edu/wp-content/uploads/2013/10/hmdb51_org.rar\n",
        "! wget http://serre-lab.clps.brown.edu/wp-content/uploads/2013/10/test_train_splits.rar"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QE0mnhzYOakH"
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.nn import functional as F\n",
        "from torch.utils.data import random_split, DataLoader, Dataset\n",
        "from torch.optim.lr_scheduler import StepLR\n",
        "import torchvision\n",
        "from torchvision import get_video_backend\n",
        "from torchvision.models.video import r3d_18 \n",
        "from torchvision import transforms\n",
        "import os\n",
        "from tqdm.auto import tqdm\n",
        "import numpy as np\n",
        "import time\n",
        "import av\n",
        "import random\n",
        "print(f\"PyAV version -- {av.__version__}\")\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "print('Using device:', device)\n",
        "\n",
        "SEED = 1\n",
        "torch.manual_seed(SEED)\n",
        "np.random.seed(SEED)\n",
        "torch.cuda.manual_seed(SEED)\n",
        "\n",
        "import copy\n",
        "from collections import OrderedDict\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "from matplotlib import pyplot as plt\n",
        "%matplotlib inline"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jeRb52LMQ6cq"
      },
      "source": [
        "# Extract and organize video data..\n",
        "! mkdir -p video_data test_train_splits\n",
        "! unrar e test_train_splits.rar test_train_splits\n",
        "! rm test_train_splits.rar\n",
        "! unrar e hmdb51_org.rar \n",
        "! rm hmdb51_org.rar\n",
        "! mv *.rar video_data\n",
        "for files in os.listdir('video_data'):\n",
        "    foldername = files.split('.')[0]\n",
        "    os.system(\"mkdir -p video_data/\" + foldername)\n",
        "    os.system(\"unrar e video_data/\"+ files + \" video_data/\"+foldername)\n",
        "\n",
        "! rm video_data/*.rar "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VmnrW4WLRF1D"
      },
      "source": [
        "# diagnostics for PyAV installation. For now version 6.2.0 works \n",
        "def run_av_diagnostics():\n",
        "    import av\n",
        "    av.open(\"video_data/brush_hair/Aussie_Brunette_Brushing_Hair_II_brush_hair_u_nm_np1_ba_goo_4.avi\")\n",
        "    print(get_video_backend())\n",
        "    av.logging.set_level(av.logging.ERROR)\n",
        "    if not hasattr(av.video.frame.VideoFrame, 'pict_type'):\n",
        "      print(\"Nah\")\n",
        "\n",
        "run_av_diagnostics()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qNYvG6R1RIYX"
      },
      "source": [
        "# download video transformation functions from below link\n",
        "! wget https://raw.githubusercontent.com/pytorch/vision/6de158c473b83cf43344a0651d7c01128c7850e6/references/video_classification/transforms.py\n",
        "import transforms as T"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5_AldiSTWkVM"
      },
      "source": [
        "# Parameters"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4HJF45OWWjok"
      },
      "source": [
        "input_channels = 3\n",
        "output_channels = 51\n",
        "batch_size = 10\n",
        "num_communication = 1\n",
        "num_local_update = 1\n",
        "num_edge_aggregation = 1\n",
        "lr = 0.0001\n",
        "num_clients = 4\n",
        "num_edges = 2\n",
        "dataset_root = 'data'\n",
        "bs_train = 8\n",
        "bs_test = 32\n",
        "gamma = 0.7\n",
        "decay_reg = 0.002\n",
        "num_frames = 16\n",
        "clip_steps = 25\n",
        "num_workers = 8\n",
        "pin_memory = True\n",
        "kwargs = {'num_workers':num_workers, 'pin_memory':True} if torch.cuda.is_available() else {'num_workers':num_workers}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gEOyesH_SUfv"
      },
      "source": [
        "# Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t89aDoRZRhDf"
      },
      "source": [
        "class VideoRecog_Model(nn.Module):\n",
        "  def __init__(self):\n",
        "      super(VideoRecog_Model, self).__init__()\n",
        "      self.base_model = nn.Sequential(*list(r3d_18(pretrained=True).children())[:-1])\n",
        "      self.fc = nn.Linear(512, 51)\n",
        "  def forward(self, x):\n",
        "      out = self.base_model(x).squeeze(4).squeeze(3).squeeze(2)\n",
        "      out = torch.log_softmax(self.fc(out), dim=1)\n",
        "      return out\n",
        "\n",
        "def set_parameter_requires_grad_video(model):\n",
        "    for param in model.parameters():\n",
        "        param.requires_grad = False\n",
        "    model.fc.weight.requires_grad = True\n",
        "    model.fc.bias.requires_grad = True\n",
        "\n",
        "global_nn = VideoRecog_Model().to(device)\n",
        "set_parameter_requires_grad_video(global_nn)\n",
        "print(global_nn)\n",
        "\n",
        "def count_parameters(model):\n",
        "    return sum(p.numel() for p in model.parameters() if p.requires_grad)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sSWWWufb60Gz"
      },
      "source": [
        "out = global_nn(torch.randn(16, 3 , 8, 112,112).cuda())\n",
        "print(count_parameters(model))\n",
        "out.size()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "07_OZH7CVqoC"
      },
      "source": [
        "# Average Weights"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mxIBo3Uc68vO"
      },
      "source": [
        "class AverageMeter(object):\n",
        "    def __init__(self):\n",
        "        self.reset()\n",
        "\n",
        "    def reset(self):\n",
        "        self.val = 0\n",
        "        self.avg = 0\n",
        "        self.sum = 0\n",
        "        self.count = 0\n",
        "\n",
        "    def update(self, val, n=1):\n",
        "        self.val = val\n",
        "        self.sum += val * n\n",
        "        self.count += n\n",
        "        self.avg = self.sum / self.count\n",
        "\n",
        "    def update_acc(self, val, n=1):\n",
        "        self.val = val/n\n",
        "        self.sum += val\n",
        "        self.count += n\n",
        "        self.avg = self.sum / self.count"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gsMnCJPFVsTO"
      },
      "source": [
        "def average_weights(w, s_num):\n",
        "    total_sample_num = sum(s_num)\n",
        "    temp_sample_num = s_num[0]\n",
        "    w_avg = copy.deepcopy(w[0])\n",
        "    for k in w_avg.keys():  \n",
        "        for i in range(1, len(w)): \n",
        "            w_avg[k] = w_avg[k] + torch.mul(w[i][k], s_num[i]/temp_sample_num)\n",
        "        w_avg[k] = torch.mul(w_avg[k], temp_sample_num/total_sample_num)\n",
        "    return w_avg"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "egmwTD8VVcXb"
      },
      "source": [
        "# Cloud"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XALzPqAEViFB"
      },
      "source": [
        "class Cloud():\n",
        "    def __init__(self, layers):\n",
        "        self.receiver_buffer = {}\n",
        "        self.state_dict = {}\n",
        "        self.id_registration = []\n",
        "        self.sample_registration = {}\n",
        "    def refresh_cloudserver(self):\n",
        "        self.receiver_buffer.clear()\n",
        "        del self.id_registration[:]\n",
        "        self.sample_registration.clear()\n",
        "        return None\n",
        "    def edge_register(self, edge):\n",
        "        self.id_registration.append(edge.id)\n",
        "        self.sample_registration[edge.id] = edge.all_trainsample_num\n",
        "        return None\n",
        "    def receive_from_edge(self, edge_id, e_state_dict):\n",
        "        self.receiver_buffer[edge_id] = e_state_dict\n",
        "        return None\n",
        "    def aggregate(self):\n",
        "        received_dict = [dict for dict in self.receiver_buffer.values()]\n",
        "        sample_num = [snum for snum in self.sample_registration.values()]\n",
        "        self.state_dict = average_weights(w=received_dict,s_num=sample_num)\n",
        "        return None\n",
        "    def send_to_edge(self, edge): \n",
        "        edge.receive_from_cloudserver(copy.deepcopy(self.state_dict))\n",
        "        return None"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zK5SsDncVd2z"
      },
      "source": [
        "# Edge"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j6FZnwNLViaj"
      },
      "source": [
        "class Edge():\n",
        "    def __init__(self, id, cids, layers):\n",
        "        self.id = id\n",
        "        self.cids = cids\n",
        "        self.receiver_buffer = {}\n",
        "        self.state_dict = {}\n",
        "        self.id_registration = []\n",
        "        self.sample_registration = {}\n",
        "        self.all_trainsample_num = 0\n",
        "        self.state_dict = layers\n",
        "    def refresh_edgeserver(self):\n",
        "        self.receiver_buffer.clear()\n",
        "        del self.id_registration[:]\n",
        "        self.sample_registration.clear()\n",
        "        return None\n",
        "    def client_register(self, client):\n",
        "        self.id_registration.append(client.id)\n",
        "        self.sample_registration[client.id] = len(client.train_loader.dataset)\n",
        "        return None\n",
        "    def receive_from_client(self, client_id, c_state_dict):\n",
        "        self.receiver_buffer[client_id] = c_state_dict\n",
        "        return None\n",
        "    def aggregate(self):\n",
        "        received_dict = [dict for dict in self.receiver_buffer.values()]\n",
        "        sample_num = [snum for snum in self.sample_registration.values()]\n",
        "        self.state_dict = average_weights(w = received_dict,s_num= sample_num)\n",
        "    def send_to_client(self, client):\n",
        "        client.receive_from_edgeserver(copy.deepcopy(self.state_dict))\n",
        "        return None\n",
        "    def send_to_cloudserver(self, cloud):\n",
        "        cloud.receive_from_edge(edge_id=self.id,e_state_dict= copy.deepcopy(self.state_dict))\n",
        "        return None\n",
        "    def receive_from_cloudserver(self, state_dict):\n",
        "        self.state_dict = state_dict\n",
        "        return None"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-1syuZvMVflc"
      },
      "source": [
        "# Client"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zBNDJCVCVitZ"
      },
      "source": [
        "class Client():\n",
        "    def __init__(self, id, train_loader, device):\n",
        "        self.id = id\n",
        "        self.train_loader = train_loader\n",
        "        self.model = VideoRecog_Model().to(device)\n",
        "        set_parameter_requires_grad_video(self.model)\n",
        "        self.receiver_buffer = {}\n",
        "        self.batch_size_train = batch_size_train\n",
        "    def set_parameter_requires_grad_video(model):\n",
        "        for param in model.parameters():\n",
        "            param.requires_grad = False\n",
        "        model.fc.weight.requires_grad = True\n",
        "        model.fc.bias.requires_grad = True\n",
        "    def local_update(self):\n",
        "        self.model.train()\n",
        "        correct, total_loss, flag = 0, 0.0, 0\n",
        "        Loss, Acc = AverageMeter(), AverageMeter()\n",
        "        optimizer = torch.optim.Adam(self.model.parameters(), lr=lr, weight_decay=decay_reg)\n",
        "        #start = time.time()\n",
        "        for epoch in range(num_local_update):  \n",
        "            for batch_id, data in enumerate(self.train_loader):\n",
        "                data, target = data[0], data[-1]\n",
        "                data, target = data.to(device), target.to(device)\n",
        "                optimizer.zero_grad()\n",
        "                output = self.model(data)\n",
        "                loss = F.nll_loss(output, target)\n",
        "                total_loss += loss.item()\n",
        "                loss.backward()\n",
        "                optimizer.step()\n",
        "                Loss.update(loss.item(), data.size(0))\n",
        "                pred = output.argmax(dim=1, keepdim=True)\n",
        "                num_corrects = pred.eq(target.view_as(pred)).sum().item()\n",
        "                correct += num_corrects\n",
        "                Acc.update_acc(num_corrects, data.size(0))\n",
        "            total_loss /= len(self.train_loader.dataset) \n",
        "        # print(f\"Takes {time.time() - start}\")        \n",
        "        return total_loss \n",
        "    def send_to_edgeserver(self, edgeserver):\n",
        "        edgeserver.receive_from_client(client_id= self.id,c_state_dict = copy.deepcopy(self.model.state_dict()))\n",
        "        return None\n",
        "    def receive_from_edgeserver(self, state_dict):\n",
        "        self.receiver_buffer = state_dict\n",
        "        return None\n",
        "    def update_model(self, new_layers):\n",
        "        self.model.load_state_dict(new_layers)\n",
        "    def sync_with_edgeserver(self):\n",
        "        self.model.load_state_dict(self.receiver_buffer)\n",
        "        return None"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nH2w8cLUZIwE"
      },
      "source": [
        "# HierFL Dataset Split"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "34owP9Mn6duC"
      },
      "source": [
        "train_tfms = torchvision.transforms.Compose([\n",
        "                                 T.ToFloatTensorInZeroOne(),\n",
        "                                 T.Resize((128, 171)),\n",
        "                                 T.RandomHorizontalFlip(),\n",
        "                                 T.Normalize(mean=[0.43216, 0.394666, 0.37645], std=[0.22803, 0.22145, 0.216989]),\n",
        "                                 T.RandomCrop((112, 112))\n",
        "                               ])  \n",
        "test_tfms =  torchvision.transforms.Compose([\n",
        "                                             T.ToFloatTensorInZeroOne(),\n",
        "                                             T.Resize((128, 171)),\n",
        "                                             T.Normalize(mean=[0.43216, 0.394666, 0.37645], std=[0.22803, 0.22145, 0.216989]),\n",
        "                                             T.CenterCrop((112, 112))\n",
        "                                             ])\n",
        "hmdb51_train = torchvision.datasets.HMDB51('video_data/', 'test_train_splits/', num_frames,\n",
        "                                                step_between_clips = clip_steps, fold=1, train=True,\n",
        "                                                transform=train_tfms, num_workers=num_workers)\n",
        "hmdb51_test = torchvision.datasets.HMDB51('video_data/', 'test_train_splits/', num_frames,\n",
        "                                                step_between_clips = clip_steps, fold=1, train=False,\n",
        "                                                transform=test_tfms, num_workers=num_workers)\n",
        "total_train_samples = len(hmdb51_train)\n",
        "print(f\"number of train samples {total_train_samples}\")\n",
        "print(f\"number of test samples {len(hmdb51_test)}\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g5au0Haw5EfV"
      },
      "source": [
        "class DatasetSplit(Dataset):\n",
        "    def __init__(self, dataset, idxs):\n",
        "        super(DatasetSplit, self).__init__()\n",
        "        self.dataset = dataset\n",
        "        self.idxs = list(idxs)\n",
        "    def __len__(self):\n",
        "        return len(self.idxs)\n",
        "    def __getitem__(self, item):\n",
        "        image, label = self.dataset[self.idxs[item]]\n",
        "        return image, label\n",
        "\n",
        "optimizer = torch.optim.Adam(global_nn.parameters(), lr=lr, weight_decay=decay_reg)\n",
        "scheduler = StepLR(optimizer, step_size=10, gamma=gamma)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hGNk0JP60YEz"
      },
      "source": [
        "train_loaders = [0] * num_clients\n",
        "num_samples_per_client = int(total_train_samples / num_clients)\n",
        "all_idxs = [i for i in range(total_train_samples)]  \n",
        "for i in range(num_clients):\n",
        "    idxs = np.random.choice(all_idxs, num_samples_per_client, replace = False)\n",
        "    all_idxs = list(set(all_idxs) - set(idxs))\n",
        "    train_loaders[i] = DataLoader(DatasetSplit(hmdb51_train, idxs), batch_size = bs_train, shuffle = True, **kwargs)\n",
        "\n",
        "test_loader  = DataLoader(hmdb51_test, batch_size=bs_test, shuffle=False, **kwargs)\n",
        "print(len(train_loaders[0].dataset))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AZooih5T4F18"
      },
      "source": [
        "# HierFL Test Loop"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zSHWiWqV5Uz6"
      },
      "source": [
        "def test(model, loader):\n",
        "  model.eval()\n",
        "  correct = 0\n",
        "  total_loss = 0.0\n",
        "  Loss, Acc = AverageMeter(), AverageMeter()\n",
        "  with torch.no_grad():\n",
        "    for batch_id, data in enumerate(loader):\n",
        "      data, target = data[0], data[-1]\n",
        "      data, target = data.to(device), target.to(device)\n",
        "      output = model(data)\n",
        "      loss = F.nll_loss(output, target)\n",
        "      total_loss += loss.item()\n",
        "      Loss.update(loss.item(), data.size(0))\n",
        "      pred = output.argmax(dim=1, keepdim=True)  \n",
        "      num_corrects = pred.eq(target.view_as(pred)).sum().item()\n",
        "      correct += num_corrects\n",
        "      Acc.update_acc(num_corrects, data.size(0))\n",
        "    total_loss /= len(loader.dataset)\n",
        "    print(text + ' Average Loss: {:.6f} Average Accuracy: {}/{} ({:.0f})%'.format(\n",
        "         Loss.avg, correct, Acc.count , 100. * Acc.avg ))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qoMZfemk3_M_"
      },
      "source": [
        "# Main HierFL Algorithm"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N1vukawIZMlQ"
      },
      "source": [
        "avg_acc_v_total = []\n",
        "client_loss_total = []\n",
        "clients = []\n",
        "edges = []\n",
        "\n",
        "for i in range(num_clients):\n",
        "    clients.append(Client(id=i,train_loader=train_loaders[i],device=device))\n",
        "cids = np.arange(num_clients)\n",
        "clients_per_edge = int(num_clients / num_edges)\n",
        "\n",
        "for i in range(num_edges):\n",
        "    selected_cids = np.random.choice(cids, clients_per_edge, replace=False)\n",
        "    cids = list (set(cids) - set(selected_cids))\n",
        "    edges.append(Edge(id = i,cids = selected_cids,layers = copy.deepcopy(clients[0].model.state_dict())))\n",
        "    [edges[i].client_register(clients[cid]) for cid in selected_cids]\n",
        "    edges[i].all_trainsample_num = sum(edges[i].sample_registration.values())\n",
        "    edges[i].refresh_edgeserver()\n",
        "\n",
        "cloud = Cloud(layers=copy.deepcopy(clients[0].model.state_dict()))\n",
        "    \n",
        "for num_comm in tqdm(range(num_communication)):\n",
        "    start = time.time()\n",
        "    cloud.refresh_cloudserver()\n",
        "    [cloud.edge_register(edge=edge) for edge in edges]\n",
        "    \n",
        "    for num_edgeagg in range(num_edge_aggregation):\n",
        "        client_loss = 0.0\n",
        "        for i,edge in enumerate(edges):\n",
        "            edge.refresh_edgeserver()\n",
        "        selected_cids = edge.cids\n",
        "        for selected_cid in selected_cids:\n",
        "            edge.client_register(clients[selected_cid])\n",
        "        for selected_cid in selected_cids:\n",
        "            edge.send_to_client(clients[selected_cid])\n",
        "            clients[selected_cid].sync_with_edgeserver()\n",
        "            client_loss += clients[selected_cid].local_update()\n",
        "            clients[selected_cid].send_to_edgeserver(edge)\n",
        "        client_loss_total.append(client_loss)    \n",
        "    \n",
        "    for edge in edges:\n",
        "        edge.send_to_cloudserver(cloud)\n",
        "    cloud.aggregate()\n",
        "    for edge in edges:\n",
        "        cloud.send_to_edge(edge)\n",
        "    global_nn.load_state_dict(state_dict = copy.deepcopy(cloud.state_dict))\n",
        "    test(global_nn, test_loader)\n",
        "    print(\"Epoch {} took {} seconds\".format(num_comm+1, time.time()-start))"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}